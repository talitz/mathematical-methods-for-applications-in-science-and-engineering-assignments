# QUESTION 4


##########################  FUNCTIONS ###########################
#-------------------- svd_decomposition factorization ---------------------

function svd_decomposition(A)

L = eig(transpose(A)*A)
b = sqrt(L[1])
S = sort(sqrt(L[1]),rev=true)
P = sortperm(sqrt(L[1]),rev=true)
V = L[2]

sorted_V = zeros(V)
row = size(V)[1]

for i in 1:length(P)
  for j in 1:row
    get_column_of_sorted_V = (i-1)*row
    current_cell = j
    column_index_to_set = P[i]
    get_column_of_V = (column_index_to_set-1) * row
    sorted_V[get_column_of_sorted_V + current_cell] = V[get_column_of_V+current_cell]
  end
end

## Calculating matrix U
id_matrix = eye(row)
inv_v = transpose(sorted_V \ id_matrix)
inv_s = diagm(S) \ id_matrix
U = A*inv_v*inv_s

return U,S,V
end
#-------------------- modified_gram_schmidt factorization ---------------------
function modified_gram_schmidt(A)
    n = size(A,2); # assume A is m√ón
    m = size(A,1);
    R = zeros(n,n);
    Q = zeros(m,n);
    R[1,1] = norm(A[:,1]);
    Q[:,1] = A[:,1]/R[1,1];

    for i=2:n
        Q[:,i] = A[:,i];
        for j=1:i-1
            R[j,i] = vecdot(Q[:,j]',Q[:,i]);
            Q[:,i] = Q[:,i] - R[j,i]*Q[:,j];
        end
        R[i,i] = norm(Q[:,i]);
        Q[:,i] = Q[:,i]/R[i,i];
    end

    return Q,R
end
#-------------------- CHOLESKY factorization ---------------------
function CHOL_factorization(new_A,new_b)
    #println("Solving with CHOLESKY factorization")
    L = chol(new_A)
    A_choled = L*transpose(L)

    # now, we solve A_choled * x = new_b
    x = inv(transpose(A_choled)*A_choled)* (transpose(A_choled)*new_b)
    #println("x = ",x)
    return x;
end
#-------------------- QR factorization ---------------------
function QR_factorization2a(new_A,new_b)
    println("Solving with QR factorization")
    Q,R = modified_gram_schmidt(new_A)

    # now, we solve Q * R * x = new_b
    # meaning, R * x = inv(Q) * new_b
    # and we get, x = inv(R) * inv(Q) * new_b

    x = inv(R) * inv(Q) * new_b
    println("x = ",x)
    return x;
end

function QR_factorization(new_A,new_b)
    #println("Solving with QR factorization")
    Q,R = qr(new_A)

    # now, we solve Q * R * x = new_b
    # meaning, R * x = inv(Q) * new_b
    # and we get, x = inv(R) * inv(Q) * new_b

    x = inv(R) * inv(Q) * new_b
    println("x = ",x)
    return x;
end

#-------------------- SVD factorization ---------------------
function SVD_factorization2a(A,new_b)
    println("Solving with SVD factorization")
    U,S,V = svd_decomposition(A)
    S = diagm(S)
    x = V * inv(S) * transpose(U) * new_b
    println("x = ",x)
    return x;
end

function SVD_factorization(A,new_b)
    #println("Solving with SVD factorization")
    U,S,V = svd(A)
    S = diagm(S)
    x = V * inv(S) * transpose(U) * new_b
    println("x = ",x)
    return x;
end
####################  end of FUNCTIONS #####################

####################### PART A ##############################
A = [2 1 2; 1 -2 1; 1 2 3; 1 1 1]
b = [6 1 5 2]

new_A = transpose(A)*A
new_b = transpose(A)*transpose(b)
# now, we solve new_A * x = new_b instead of Ax = b
QR_factorization(new_A,new_b)
SVD_factorization(new_A,new_b)

####################### PART C ##############################

## Define
println("PART C")
#println("compare the accuracy of the obtained LS solution using the three
#methods:")
m = 100; n = 25; k = 10; s = rand(n);
xi_chols = []; xi_QRS = []; xi_SVDS = []; condA = [];

for i = 1 : 10
  sigma = exp(i*rand(n));
  A = randn(m,n)*diagm(sigma)*randn(n,n);
  b = A*s;
  # solutions of the LS problem
  new_A = A'*A
  new_b = A'*b
  xi_chol = CHOL_factorization(new_A,new_b)
  xi_QR = QR_factorization(new_A,new_b)
  xi_SVD = SVD_factorization(new_A,new_b)

  # error norms
  err_i_cholesky = norm(xi_chol - s)
  err_i_QR = norm(xi_QR - s)
  err_i_SVD = norm(xi_SVD - s)
  push!(xi_chols, err_i_cholesky)
  push!(xi_QRS, err_i_QR)
  push!(xi_SVDS, err_i_SVD)
  push!(condA, cond(A))

end

####################### Graph ##############################

using PyPlot
figure();
subplot(1,2,1);
y = xi_chols;
semilogy(1 : 10,y,"-b");
y = xi_QRS;
semilogy(1 : 10,y,"-r");
y = xi_SVDS;
semilogy(1 : 10,y,"-g");

title("Compare the accuracy of the obtained LS solution");
legend(("chol", "qr", "svd"));
xlabel("1:10");
ylabel("Error Norm");


subplot(1,2,2);
y = condA;
semilogy(1 : 10,y,"-y");
title("Condition number");
show();

####################### Methods performance ##############################
#The Methods perform according to the cond of matrix A.
#Meaning, when the cond of matrix A is higher then error is bigger.
#=
ADD IT : ???????
In addition, in every change in cond(A), for example when it decreases around x=8,
the solution in each one of the methods improves i.e. the error decreases.
This result is reasonable since by definition, cond(A) measures the change in vector x in relation to the change in the vector b,
meaning the size of the error. Therefore, as cond(A) increases so does the error, as required.
=#

####################### Best Method ##############################
#By the results, we can say that QR and SVD are almost the same.
#but we learned in class that svd is more pricely than qr.
#For svd we need the eigenvalues (expensive process), therefore the qr is the best method
#in terms of computing time and accuracy.
